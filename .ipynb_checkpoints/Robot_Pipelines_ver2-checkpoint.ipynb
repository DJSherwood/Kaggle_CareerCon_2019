{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "import logging\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from subprocess import check_output\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectPercentile, mutual_info_regression\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.impute import MissingIndicator\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, GroupShuffleSplit\n",
    "#from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import reciprocal, uniform\n",
    "\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('X_train.csv')\n",
    "test = pd.read_csv('X_test.csv')\n",
    "y = pd.read_csv('y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.set_index('series_id').join(y.set_index('series_id'))\n",
    "trainb = train.loc[train['group_id'].isin([2,7,13,23,37,49])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: feature engineering: A) convert to euler B) polynomial features\n",
    "quats = ['orientation_X','orientation_Y','orientation_Z','orientation_W']\n",
    "feat_engineering = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('add_features', PolynomialFeatures(degree=2,interaction_only=True,include_bias=False), quats )\n",
    "    ]\n",
    ")\n",
    "\n",
    "## Step 2: standardize? I need to think carefully about my cross-validation scheme\n",
    "try_pipe = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('add_features', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    ('standardize', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step3: LabelEncode\n",
    "encoded_response=pd.DataFrame()\n",
    "instance_LabelEncoder = LabelEncoder()\n",
    "encoded_response['surface'] = instance_LabelEncoder.fit_transform(trainb['surface'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See these references\n",
    "https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py\n",
    "\n",
    "https://scikit-learn.org/stable/modules/grid_search.html#grid-search\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit\n",
    "\n",
    "https://www.kaggle.com/prathamsolanki/can-xgboost-help-robots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pipe = Pipeline([\n",
    "    ('pipeline', try_pipe),\n",
    "    ('classif', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "parameters = [\n",
    "                  {\n",
    "                      'classif__max_depth': [8,10,12],\n",
    "                      'classif__n_estimators': [5, 10, 15],\n",
    "                      'classif__min_samples_leaf': [2,4]\n",
    "                  }\n",
    "             ]\n",
    "\n",
    "# Define addtional variables in hopes of increasing readability\n",
    "X_data = train[['orientation_X','orientation_Y','orientation_Z','orientation_W','angular_velocity_X','angular_velocity_Y','angular_velocity_Z','linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z']]\n",
    "y_data = encoded_response['surface']\n",
    "grp_data = train['group_id']\n",
    "X = X_data.values\n",
    "y = y_data.values\n",
    "\n",
    "# Instantiate groupshufflesplit\n",
    "gss = GroupShuffleSplit(n_splits = 9, test_size = 0.2, random_state=42)\n",
    "\n",
    "model_list={}\n",
    "score=[]\n",
    "# Loop through the training/testing indicies for cross validation\n",
    "for i, (train_indices, val_indices) in enumerate(gss.split(X = X_data, y=y_data, groups=grp_data)):\n",
    "    \n",
    "    # Define training and test sets\n",
    "    X_train, X_valid = X[train_indices], X[val_indices]\n",
    "    y_train, y_valid = y[train_indices], y[val_indices]\n",
    "       \n",
    "    #print('Train Size: %s | Test: %s' % (train_indices.shape, val_indices.shape))\n",
    "    \n",
    "    # Define name for dictionary\n",
    "    name=str('GroupFold') + str(i)\n",
    "    \n",
    "    # Perform cross-validation within a loop\n",
    "    GrdSrch = GridSearchCV(class_pipe, parameters, verbose=2, cv = 3, scoring='accuracy')\n",
    "    classif = GrdSrch.fit(X_train, y_train)\n",
    "    score[i] = classif.score(X_valid, y_valid)\n",
    "    print(\"{} score: {}\".format(name, score))\n",
    "    \n",
    "    model_list[name] = classif\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Me ver 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps of the chain should not be Pipelines",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c80b8218924c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m     class_pipe = Pipeline([\n\u001b[1;32m     30\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m'pipeline'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtry_pipe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0;34m'classif'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     ])\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_comps/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kaggle_comps/lib/python3.6/site-packages/imblearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 raise TypeError(\n\u001b[0;32m--> 146\u001b[0;31m                     \u001b[0;34m\"All intermediate steps of the chain should not be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                     \" Pipelines\")\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps of the chain should not be Pipelines"
     ]
    }
   ],
   "source": [
    "# Define addtional variables in hopes of increasing readability\n",
    "X_data = trainb[['orientation_X','orientation_Y','orientation_Z','orientation_W','angular_velocity_X','angular_velocity_Y','angular_velocity_Z','linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z']]\n",
    "y_data = encoded_response['surface']\n",
    "grp_data = trainb['group_id']\n",
    "\n",
    "## I think this will work\n",
    "\n",
    "names = [\n",
    "         \"Random Forest Classifier\"\n",
    "        ]\n",
    "\n",
    "classifier = [\n",
    "    RandomForestClassifier()\n",
    "]\n",
    "\n",
    "parameters = [\n",
    "                  {\n",
    "                      'classif__max_depth': [12],\n",
    "                      'classif__n_estimators': [5, 15],\n",
    "                      'classif__min_samples_leaf': [4]\n",
    "                  }\n",
    "             ]\n",
    "\n",
    "\n",
    "model_list = {}\n",
    "for name, classifier, params in zip(names, classifier, parameters):\n",
    "    \n",
    "    ## Append classifier to pipe\n",
    "    class_pipe = Pipeline([\n",
    "        ('pipeline', try_pipe),\n",
    "        ('classif', classifier)\n",
    "    ])\n",
    "    \n",
    "    ## Attach StratifiedKFold or whatever to CV\n",
    "    GrdSrch = GridSearchCV(class_pipe, params, verbose=2, scoring='accuracy')\n",
    "    gs_classif = GrdSrch.fit(X_data, y_data)\n",
    "    model_list[name] = gs_classif\n",
    "    \n",
    "    ## Use cross_val_score\n",
    "    score = cross_val_score(gs_classif, X=X_data, y=y_data, cv=GroupShuffleSplit().split(X=X_data, y=y_data, groups=grp_data))\n",
    "    print(\"{} score: {}\".format(name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list['Random Forest Classifier'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Predictions\n",
    "y_hat = gs_classif.best_estimator_.predict(test[['orientation_X','orientation_Y','orientation_Z','orientation_W', \\\n",
    "                                                        'angular_velocity_X','angular_velocity_Y','angular_velocity_Z', \\\n",
    "                                                        'linear_acceleration_X','linear_acceleration_Y','linear_acceleration_Z']])\n",
    "\n",
    "## Transform back to labels\n",
    "test['surface'] = instance_LabelEncoder.inverse_transform(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join to submission file\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "answers = test.groupby('series_id').first()[['surface']]\n",
    "submission['surface'] = answers['surface']\n",
    "\n",
    "## save as csv\n",
    "submission.to_csv('submission_3Apr2019_djs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>> y_hat = pipeline.predict(X_test)\n",
    "#>>> print(classification_report(y_test, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
